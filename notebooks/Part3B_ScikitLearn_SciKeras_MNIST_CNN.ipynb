{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cfccf03",
   "metadata": {},
   "source": [
    "# Part 3D — MNIST CNN with scikit‑learn (via SciKeras)\n",
    "_Last updated: 2025-11-16_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3524944",
   "metadata": {},
   "source": [
    "\n",
    "`scikit-learn` doesn’t implement CNNs natively, so we use the **SciKeras** wrapper to expose a Keras\n",
    "model through the familiar `fit/score` API (and GridSearchCV). This still runs with TensorFlow under the hood.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f227c88",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, time, json, pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Devices:\", tf.config.list_physical_devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33f86e",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset & preprocessing\n",
    "\n",
    "We use **MNIST** (28×28 grayscale digits, 10 classes). Input is normalized to `[0, 1]`\n",
    "and reshaped to `(N, 28, 28, 1)` for CNNs. Labels are integers `0..9`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f2a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x = np.concatenate([x_train, x_test]).astype(\"float32\")/255.0\n",
    "y = np.concatenate([y_train, y_test]).astype(\"int64\")\n",
    "x = np.expand_dims(x, -1)\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e09e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=1e-3):\n",
    "    inputs = keras.Input(shape=(28,28,1))\n",
    "    x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                  loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9814e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KerasClassifier(model=make_model, epochs=5, batch_size=128, verbose=0)\n",
    "# Optional: quick hyperparam search (tiny grid for demo)\n",
    "param_grid = {\"model__learning_rate\":[1e-3, 5e-4]}\n",
    "t0=time.perf_counter()\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=3, n_jobs=1)\n",
    "grid.fit(Xtr, ytr)\n",
    "train_time=time.perf_counter()-t0\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "y_pred = grid.predict(Xte)\n",
    "test_acc = accuracy_score(yte, y_pred)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c49393d",
   "metadata": {},
   "source": [
    "## Plot training history (from the best estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c99b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = grid.best_estimator_\n",
    "hist = best.model_.history.history if hasattr(best.model_, \"history\") else None\n",
    "if hist:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    if \"loss\" in hist: plt.plot(hist[\"loss\"], label=\"train_loss\")\n",
    "    if \"val_loss\" in hist: plt.plot(hist[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.grid(True); plt.title(\"SciKeras: loss\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"artifacts/sklearn_loss.png\", dpi=150)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc1c16",
   "metadata": {},
   "source": [
    "## Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98271841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: save artifacts (plots & metrics)\n",
    "import os, json, pathlib, time\n",
    "ART = pathlib.Path(\"artifacts\")\n",
    "ART.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(name, **metrics):\n",
    "    path = ART / f\"{name}_metrics.json\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    print(\"Saved:\", path)\n",
    "\n",
    "def effective_loc(*funcs):\n",
    "    import inspect\n",
    "    n = 0\n",
    "    for f in funcs:\n",
    "        try:\n",
    "            src = inspect.getsource(f)\n",
    "            for line in src.splitlines():\n",
    "                s = line.strip()\n",
    "                if s and not s.startswith(\"#\"):\n",
    "                    n += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee36919",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best.model_.count_params() if hasattr(best, \"model_\") else None\n",
    "save_metrics(\"sklearn\", framework=\"scikit-learn+scikeras\", test_accuracy=float(test_acc),\n",
    "             test_loss=float(\"nan\"), train_time_sec=float(train_time), params=int(params or 0),\n",
    "             epochs=int(len(hist[\"loss\"])) if hist else 0,\n",
    "             device=str(tf.config.list_physical_devices(\"GPU\") or tf.config.list_physical_devices(\"CPU\")),\n",
    "             effective_loc=int(effective_loc(make_model)))\n",
    "print(\"Saved artifacts/ and metrics.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Part 3D — MNIST CNN with scikit‑learn (via SciKeras)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
