{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e6f931",
   "metadata": {},
   "source": [
    "# Part 3C — MNIST CNN with PyTorch\n",
    "_Last updated: 2025-11-16_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390b0156",
   "metadata": {},
   "source": [
    "\n",
    "This notebook implements a compact **PyTorch** CNN using `torchvision` datasets and a simple\n",
    "training loop. It auto-detects **CUDA**, **MPS** (Apple Silicon), or **CPU**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e021b4",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969acedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, time, json, pathlib, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "print(\"Device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "try:\n",
    "    torch.set_float32_matmul_precision(\"medium\")\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f28e5a9",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset & preprocessing\n",
    "\n",
    "We use **MNIST** (28×28 grayscale digits, 10 classes). Input is normalized to `[0, 1]`\n",
    "and reshaped to `(N, 28, 28, 1)` for CNNs. Labels are integers `0..9`.\n",
    "\n",
    "We use `torchvision.datasets.MNIST` and standard normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716d0858",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfm = transforms.Compose([transforms.ToTensor()])  # converts to [0,1] and adds channel dim\n",
    "train_ds = datasets.MNIST(root=\"data\", train=True, download=True, transform=tfm)\n",
    "test_ds  = datasets.MNIST(root=\"data\", train=False, download=True, transform=tfm)\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2, pin_memory=(device.type==\"cuda\"))\n",
    "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False, num_workers=2, pin_memory=(device.type==\"cuda\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7935946",
   "metadata": {},
   "source": [
    "## Model + training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbcc05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1,32,3), nn.ReLU(),\n",
    "            nn.Conv2d(32,64,3), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216,128), nn.ReLU(),\n",
    "            nn.Linear(128,10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = Net().to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    ls=0.0; n=0\n",
    "    for x,y in train_loader:\n",
    "        x = x.to(device, non_blocking=True); y = y.to(device, non_blocking=True)\n",
    "        opt.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        ls += float(loss.item()); n += 1\n",
    "    return ls/max(n,1)\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    correct=0; total=0; ls=0.0; n=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_loader:\n",
    "            x = x.to(device, non_blocking=True); y = y.to(device, non_blocking=True)\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "            pred = logits.argmax(1)\n",
    "            correct += int((pred==y).sum().item()); total += int(y.numel())\n",
    "            ls += float(loss.item()); n += 1\n",
    "    return ls/max(n,1), correct/total\n",
    "\n",
    "EPOCHS=5\n",
    "t0=time.perf_counter()\n",
    "train_hist=[]; val_hist=[]\n",
    "for epoch in range(EPOCHS):\n",
    "    tl=train_epoch(); vl,va=evaluate()\n",
    "    train_hist.append(tl); val_hist.append(vl)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - loss {tl:.4f} - val_loss {vl:.4f} - val_acc {va:.4f}\")\n",
    "train_time=time.perf_counter()-t0\n",
    "test_loss, test_acc = evaluate()\n",
    "print(\"Test acc:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a391e3a",
   "metadata": {},
   "source": [
    "## Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2504f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(train_hist, label=\"train_loss\")\n",
    "plt.plot(val_hist, label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.grid(True); plt.title(\"PyTorch: loss\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"artifacts/pytorch_loss.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a44281",
   "metadata": {},
   "source": [
    "## Save metrics & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb323bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Utility: save artifacts (plots & metrics)\n",
    "import os, json, pathlib, time\n",
    "ART = pathlib.Path(\"artifacts\")\n",
    "ART.mkdir(exist_ok=True)\n",
    "\n",
    "def save_metrics(name, **metrics):\n",
    "    path = ART / f\"{name}_metrics.json\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    print(\"Saved:\", path)\n",
    "\n",
    "def effective_loc(*funcs):\n",
    "    import inspect\n",
    "    n = 0\n",
    "    for f in funcs:\n",
    "        try:\n",
    "            src = inspect.getsource(f)\n",
    "            for line in src.splitlines():\n",
    "                s = line.strip()\n",
    "                if s and not s.startswith(\"#\"):\n",
    "                    n += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "    return n\n",
    "\n",
    "save_metrics(\"pytorch\", framework=\"pytorch\", test_accuracy=float(test_acc), test_loss=float(test_loss),\n",
    "             train_time_sec=float(train_time), params=int(sum(p.numel() for p in model.parameters())),\n",
    "             epochs=len(train_hist), device=str(device),\n",
    "             effective_loc=int(effective_loc(Net, train_epoch, evaluate)))\n",
    "torch.save(model.state_dict(), \"artifacts/pytorch_mnist.pt\")\n",
    "print(\"Saved artifacts/ and metrics.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Part 3C — MNIST CNN with PyTorch",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
